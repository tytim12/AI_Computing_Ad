{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. All changes under this directory will be kept even after reset. Please clean unnecessary files in time to speed up environment loading.\n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, you need to use the persistence path as the following:\n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可:\r\n",
    "# Also add the following code, so that every time the environment (kernel) starts, just run the following code:\r\n",
    "import sys\r\n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\r\n",
      "Requirement already satisfied: xgboost in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from xgboost) (1.16.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from xgboost) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gc\r\n",
    "import pandas as pd\r\n",
    "# 用户行为，使用format1进行加载\r\n",
    "# 加载全量样本\r\n",
    "\r\n",
    "user_log = pd.read_csv('/home/aistudio/data/data30922/user_log1.csv', dtype={'time_stamp':'str'})\r\n",
    "user_info = pd.read_csv('user_info1.csv')\r\n",
    "train_data1 = pd.read_csv('train_format1.csv')\r\n",
    "submission = pd.read_csv('test_format1.csv')\r\n",
    "\"\"\"\r\n",
    "# 加载小样本\r\n",
    "user_log = pd.read_csv('./data_format1_small/sample_user_log.csv', dtype={'time_stamp':'str'})\r\n",
    "user_info = pd.read_csv('./data_format1_small/sample_user_info.csv')\r\n",
    "train_data1 = pd.read_csv('./data_format1_small/train.csv')\r\n",
    "submission = pd.read_csv('./data_format1_small/test.csv')\r\n",
    "\"\"\"\r\n",
    "train_data = pd.read_csv('/home/aistudio/data/data30922/train_format2.csv')\r\n",
    "\r\n",
    "train_data1['origin'] = 'train'\r\n",
    "submission['origin'] = 'test'\r\n",
    "matrix = pd.concat([train_data1, submission], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix.drop(['prob'], axis=1, inplace=True)\r\n",
    "\r\n",
    "# 连接user_info表，通过user_id关联\r\n",
    "matrix = matrix.merge(user_info, on='user_id', how='left')\r\n",
    "\r\n",
    "# 使用merchant_id（原列名seller_id）\r\n",
    "user_log.rename(columns={'seller_id':'merchant_id'}, inplace=True)\r\n",
    "\r\n",
    "# 格式化\r\n",
    "user_log['user_id'] = user_log['user_id'].astype('int32')\r\n",
    "user_log['merchant_id'] = user_log['merchant_id'].astype('int32')\r\n",
    "user_log['item_id'] = user_log['item_id'].astype('int32')\r\n",
    "user_log['cat_id'] = user_log['cat_id'].astype('int32')\r\n",
    "user_log['brand_id'].fillna(0, inplace=True)\r\n",
    "user_log['brand_id'] = user_log['brand_id'].astype('int32')\r\n",
    "user_log['time_stamp'] = pd.to_datetime(user_log['time_stamp'], format='%H%M')\r\n",
    "\r\n",
    "# 1 for <18; 2 for [18,24]; 3 for [25,29]; 4 for [30,34]; 5 for [35,39]; 6 for [40,49]; 7 and 8 for >= 50; 0 and NULL for unknown\r\n",
    "matrix['age_range'].fillna(0, inplace=True)\r\n",
    "\r\n",
    "# 0:female, 1:male, 2:unknown\r\n",
    "matrix['gender'].fillna(2, inplace=True)\r\n",
    "matrix['age_range'] = matrix['age_range'].astype('int8')\r\n",
    "matrix['gender'] = matrix['gender'].astype('int8')\r\n",
    "matrix['label'] = matrix['label'].astype('str')\r\n",
    "matrix['user_id'] = matrix['user_id'].astype('int32')\r\n",
    "matrix['merchant_id'] = matrix['merchant_id'].astype('int32')\r\n",
    "del user_info, train_data1\r\n",
    "gc.collect()\r\n",
    "# print(matrix)\r\n",
    "\r\n",
    "# User特征处理\r\n",
    "groups = user_log.groupby(['user_id'])\r\n",
    "# 用户交互行为数量 u1\r\n",
    "temp = groups.size().reset_index().rename(columns={0:'u1'})\r\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\r\n",
    "# 使用agg 基于列的聚合操作，统计唯一值的个数 item_id, cat_id, merchant_id, brand_id\r\n",
    "#temp = groups['item_id', 'cat_id', 'merchant_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'u2', 'cat_id':'u3', 'merchant_id':'u4', 'brand_id':'u5'})\r\n",
    "temp = groups['item_id'].agg([('u2', 'nunique')]).reset_index()\r\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\r\n",
    "temp = groups['cat_id'].agg([('u3', 'nunique')]).reset_index()\r\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\r\n",
    "temp = groups['merchant_id'].agg([('u4', 'nunique')]).reset_index()\r\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\r\n",
    "temp = groups['brand_id'].agg([('u5', 'nunique')]).reset_index()\r\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\r\n",
    "\r\n",
    "# 时间间隔特征 u6 按照小时\r\n",
    "temp = groups['time_stamp'].agg([('F_time', 'min'), ('L_time', 'max')]).reset_index()\r\n",
    "temp['u6'] = (temp['L_time'] - temp['F_time']).dt.seconds/3600\r\n",
    "matrix = matrix.merge(temp[['user_id', 'u6']], on='user_id', how='left')\r\n",
    "# 统计操作类型为0，1，2，3的个数\r\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'u7', 1:'u8', 2:'u9', 3:'u10'})\r\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\r\n",
    "#print(matrix)\r\n",
    "\r\n",
    "# 商家特征处理\r\n",
    "groups = user_log.groupby(['merchant_id'])\r\n",
    "# 商家被交互行为数量 m1\r\n",
    "temp = groups.size().reset_index().rename(columns={0:'m1'})\r\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\r\n",
    "# 统计商家被交互的user_id, item_id, cat_id, brand_id 唯一值\r\n",
    "temp = groups['user_id', 'item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'user_id':'m2', 'item_id':'m3', 'cat_id':'m4', 'brand_id':'m5'})\r\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\r\n",
    "# 统计商家被交互的action_type 唯一值\r\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'m6', 1:'m7', 2:'m8', 3:'m9'})\r\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\r\n",
    "# 按照merchant_id 统计随机负采样的个数\r\n",
    "temp = train_data[train_data['label']==-1].groupby(['merchant_id']).size().reset_index().rename(columns={0:'m10'})\r\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\r\n",
    "#print(matrix)\r\n",
    "\r\n",
    "# 按照user_id, merchant_id分组\r\n",
    "groups = user_log.groupby(['user_id', 'merchant_id'])\r\n",
    "temp = groups.size().reset_index().rename(columns={0:'um1'}) #统计行为个数\r\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\r\n",
    "temp = groups['item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'um2', 'cat_id':'um3', 'brand_id':'um4'}) #统计item_id, cat_id, brand_id唯一个数\r\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\r\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'um5', 1:'um6', 2:'um7', 3:'um8'})#统计不同action_type唯一个数\r\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\r\n",
    "temp = groups['time_stamp'].agg([('first', 'min'), ('last', 'max')]).reset_index()\r\n",
    "temp['um9'] = (temp['last'] - temp['first']).dt.seconds/3600\r\n",
    "temp.drop(['first', 'last'], axis=1, inplace=True)\r\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left') #统计时间间隔\r\n",
    "#print(matrix)\r\n",
    "\r\n",
    "#用户购买点击比\r\n",
    "matrix['r1'] = matrix['u9']/matrix['u7'] \r\n",
    "#商家购买点击比\r\n",
    "matrix['r2'] = matrix['m8']/matrix['m6'] \r\n",
    "#不同用户不同商家购买点击比\r\n",
    "matrix['r3'] = matrix['um7']/matrix['um5']\r\n",
    "matrix.fillna(0, inplace=True)\r\n",
    "# # 修改age_range字段名称为 age_0, age_1, age_2... age_8\r\n",
    "temp = pd.get_dummies(matrix['age_range'], prefix='age')\r\n",
    "matrix = pd.concat([matrix, temp], axis=1)\r\n",
    "temp = pd.get_dummies(matrix['gender'], prefix='g')\r\n",
    "matrix = pd.concat([matrix, temp], axis=1)\r\n",
    "matrix.drop(['age_range', 'gender'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分割训练数据和测试数据\r\n",
    "train_data = matrix[matrix['origin'] == 'train'].drop(['origin'], axis=1)\r\n",
    "test_data = matrix[matrix['origin'] == 'test'].drop(['label', 'origin'], axis=1)\r\n",
    "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']\r\n",
    "del temp, matrix\r\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.63901\tvalidation_1-auc:0.62369\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-auc:0.65549\tvalidation_1-auc:0.64045\n",
      "[2]\tvalidation_0-auc:0.66038\tvalidation_1-auc:0.64475\n",
      "[3]\tvalidation_0-auc:0.66698\tvalidation_1-auc:0.64872\n",
      "[4]\tvalidation_0-auc:0.66771\tvalidation_1-auc:0.64907\n",
      "[5]\tvalidation_0-auc:0.66827\tvalidation_1-auc:0.65126\n",
      "[6]\tvalidation_0-auc:0.66991\tvalidation_1-auc:0.64928\n",
      "[7]\tvalidation_0-auc:0.66988\tvalidation_1-auc:0.64876\n",
      "[8]\tvalidation_0-auc:0.67096\tvalidation_1-auc:0.64969\n",
      "[9]\tvalidation_0-auc:0.67242\tvalidation_1-auc:0.65052\n",
      "[10]\tvalidation_0-auc:0.67404\tvalidation_1-auc:0.65128\n",
      "[11]\tvalidation_0-auc:0.67545\tvalidation_1-auc:0.65231\n",
      "[12]\tvalidation_0-auc:0.67731\tvalidation_1-auc:0.65303\n",
      "[13]\tvalidation_0-auc:0.67883\tvalidation_1-auc:0.65399\n",
      "[14]\tvalidation_0-auc:0.68110\tvalidation_1-auc:0.65427\n",
      "[15]\tvalidation_0-auc:0.68422\tvalidation_1-auc:0.65677\n",
      "[16]\tvalidation_0-auc:0.68555\tvalidation_1-auc:0.65813\n",
      "[17]\tvalidation_0-auc:0.68620\tvalidation_1-auc:0.65768\n",
      "[18]\tvalidation_0-auc:0.68778\tvalidation_1-auc:0.65849\n",
      "[19]\tvalidation_0-auc:0.68888\tvalidation_1-auc:0.65920\n",
      "[20]\tvalidation_0-auc:0.69040\tvalidation_1-auc:0.66018\n",
      "[21]\tvalidation_0-auc:0.69126\tvalidation_1-auc:0.66021\n",
      "[22]\tvalidation_0-auc:0.69243\tvalidation_1-auc:0.66054\n",
      "[23]\tvalidation_0-auc:0.69319\tvalidation_1-auc:0.66060\n",
      "[24]\tvalidation_0-auc:0.69369\tvalidation_1-auc:0.66075\n",
      "[25]\tvalidation_0-auc:0.69536\tvalidation_1-auc:0.66226\n",
      "[26]\tvalidation_0-auc:0.69705\tvalidation_1-auc:0.66364\n",
      "[27]\tvalidation_0-auc:0.69819\tvalidation_1-auc:0.66359\n",
      "[28]\tvalidation_0-auc:0.69945\tvalidation_1-auc:0.66434\n",
      "[29]\tvalidation_0-auc:0.70022\tvalidation_1-auc:0.66441\n",
      "[30]\tvalidation_0-auc:0.70111\tvalidation_1-auc:0.66466\n",
      "[31]\tvalidation_0-auc:0.70163\tvalidation_1-auc:0.66534\n",
      "[32]\tvalidation_0-auc:0.70250\tvalidation_1-auc:0.66523\n",
      "[33]\tvalidation_0-auc:0.70313\tvalidation_1-auc:0.66487\n",
      "[34]\tvalidation_0-auc:0.70411\tvalidation_1-auc:0.66554\n",
      "[35]\tvalidation_0-auc:0.70473\tvalidation_1-auc:0.66553\n",
      "[36]\tvalidation_0-auc:0.70517\tvalidation_1-auc:0.66583\n",
      "[37]\tvalidation_0-auc:0.70582\tvalidation_1-auc:0.66625\n",
      "[38]\tvalidation_0-auc:0.70661\tvalidation_1-auc:0.66642\n",
      "[39]\tvalidation_0-auc:0.70722\tvalidation_1-auc:0.66719\n",
      "[40]\tvalidation_0-auc:0.70792\tvalidation_1-auc:0.66749\n",
      "[41]\tvalidation_0-auc:0.70843\tvalidation_1-auc:0.66805\n",
      "[42]\tvalidation_0-auc:0.70882\tvalidation_1-auc:0.66832\n",
      "[43]\tvalidation_0-auc:0.70973\tvalidation_1-auc:0.66828\n",
      "[44]\tvalidation_0-auc:0.70999\tvalidation_1-auc:0.66775\n",
      "[45]\tvalidation_0-auc:0.71042\tvalidation_1-auc:0.66748\n",
      "[46]\tvalidation_0-auc:0.71105\tvalidation_1-auc:0.66761\n",
      "[47]\tvalidation_0-auc:0.71144\tvalidation_1-auc:0.66809\n",
      "[48]\tvalidation_0-auc:0.71183\tvalidation_1-auc:0.66829\n",
      "[49]\tvalidation_0-auc:0.71267\tvalidation_1-auc:0.66904\n",
      "[50]\tvalidation_0-auc:0.71320\tvalidation_1-auc:0.66863\n",
      "[51]\tvalidation_0-auc:0.71418\tvalidation_1-auc:0.66887\n",
      "[52]\tvalidation_0-auc:0.71479\tvalidation_1-auc:0.66931\n",
      "[53]\tvalidation_0-auc:0.71558\tvalidation_1-auc:0.66928\n",
      "[54]\tvalidation_0-auc:0.71608\tvalidation_1-auc:0.66952\n",
      "[55]\tvalidation_0-auc:0.71697\tvalidation_1-auc:0.66977\n",
      "[56]\tvalidation_0-auc:0.71743\tvalidation_1-auc:0.66975\n",
      "[57]\tvalidation_0-auc:0.71827\tvalidation_1-auc:0.67040\n",
      "[58]\tvalidation_0-auc:0.71858\tvalidation_1-auc:0.67064\n",
      "[59]\tvalidation_0-auc:0.71908\tvalidation_1-auc:0.67054\n",
      "[60]\tvalidation_0-auc:0.71987\tvalidation_1-auc:0.67022\n",
      "[61]\tvalidation_0-auc:0.72027\tvalidation_1-auc:0.67014\n",
      "[62]\tvalidation_0-auc:0.72050\tvalidation_1-auc:0.67040\n",
      "[63]\tvalidation_0-auc:0.72090\tvalidation_1-auc:0.66993\n",
      "[64]\tvalidation_0-auc:0.72147\tvalidation_1-auc:0.67030\n",
      "[65]\tvalidation_0-auc:0.72177\tvalidation_1-auc:0.67001\n",
      "[66]\tvalidation_0-auc:0.72211\tvalidation_1-auc:0.66996\n",
      "[67]\tvalidation_0-auc:0.72299\tvalidation_1-auc:0.67014\n",
      "[68]\tvalidation_0-auc:0.72333\tvalidation_1-auc:0.67031\n",
      "Stopping. Best iteration:\n",
      "[58]\tvalidation_0-auc:0.71858\tvalidation_1-auc:0.67064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用机器学习工具\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "import xgboost as xgb\r\n",
    "# 将训练集进行切分，20%用于验证\r\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_y, test_size=.2)\r\n",
    "\r\n",
    "# 使用XGBoost\r\n",
    "model = xgb.XGBClassifier(\r\n",
    "    max_depth=8,\r\n",
    "    n_estimators=1000,\r\n",
    "    min_child_weight=300, \r\n",
    "    colsample_bytree=0.8, \r\n",
    "    subsample=0.8, \r\n",
    "    eta=0.3,    \r\n",
    "    seed=42    \r\n",
    ")\r\n",
    "model.fit(\r\n",
    "    X_train, y_train,\r\n",
    "    eval_metric='auc', eval_set=[(X_train, y_train), (X_valid, y_valid)],\r\n",
    "    verbose=True,\r\n",
    "    #早停法，如果auc在10epoch没有进步就stop\r\n",
    "    early_stopping_rounds=10 \r\n",
    ")\r\n",
    "\r\n",
    "\r\n",
    "model.fit(X_train, y_train)\r\n",
    "\r\n",
    "prob = model.predict_proba(test_data)\r\n",
    "submission['prob'] = pd.Series(prob[:,1])\r\n",
    "submission.drop(['origin'], axis=1, inplace=True)\r\n",
    "submission.to_csv('prediction.csv', index=False)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prd = pd.read_csv('prediction.csv', nrows=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163968</td>\n",
       "      <td>4605</td>\n",
       "      <td>0.071475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360576</td>\n",
       "      <td>1581</td>\n",
       "      <td>0.213795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98688</td>\n",
       "      <td>1964</td>\n",
       "      <td>0.048215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98688</td>\n",
       "      <td>3645</td>\n",
       "      <td>0.029168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>295296</td>\n",
       "      <td>3361</td>\n",
       "      <td>0.053790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id      prob\n",
       "0   163968         4605  0.071475\n",
       "1   360576         1581  0.213795\n",
       "2    98688         1964  0.048215\n",
       "3    98688         3645  0.029168\n",
       "4   295296         3361  0.053790"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.7.1 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
