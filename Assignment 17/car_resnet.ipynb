{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import scipy.io as sio\n",
    "\n",
    "# 超参数\n",
    "EPOCH = 5\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "DOWNLOAD_MNIST = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('cars_annos.mat')\n",
    "class_names = data['class_names']\n",
    "f_class = open('./label_map.txt','w')\n",
    " \n",
    "num = 1\n",
    "for j in range(class_names.shape[1]):\n",
    "    class_name = str(class_names[0,j][0]).replace(' ','_')\n",
    "#     print(num,class_name)\n",
    "    f_class.write( str(num) + ' ' + class_name + '\\n')\n",
    "    num = num + 1\n",
    "f_class.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('cars_annos.mat')\n",
    "annotations = data['annotations']\n",
    "f_train = open('./mat2txt.txt','w')\n",
    "\n",
    "num = 1\n",
    "for i in range(annotations.shape[1]):\n",
    "    name = str(annotations[0,i][0])[2:-2]\n",
    "    test  = int(annotations[0,i][6])\n",
    "    clas = int(annotations[0,i][5])\n",
    "\n",
    "    name = str(name)\n",
    "    clas = str(clas)\n",
    "    test = str(test)\n",
    "    f_train.write(str(num) + ' ' + name + ' ' + clas + ' ' + test+'\\n')\n",
    "    num = num + 1\n",
    "\n",
    "\n",
    "f_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 老数据集用这个\n",
    "\n",
    "data = sio.loadmat('cars_train_annos.mat')\n",
    "annotations = data['annotations']\n",
    "f_train = open('./train.txt','w')\n",
    " \n",
    "for i in range(annotations.shape[1]):\n",
    "    num = int(annotations[0,i][4])\n",
    "    num = str(num)\n",
    "#     print(i,num)\n",
    "    f_train.write(num+'\\n')\n",
    "\n",
    "\n",
    "f_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL 读取 image\n",
    "def default_loader(path='./data/cars_train'):\n",
    "    try:\n",
    "        img = Image.open(path)\n",
    "        return img.convert('RGB')\n",
    "    except:\n",
    "        print(f'Cannot read image: {path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customData(Dataset):\n",
    "    \n",
    "    # 将图片路径存入self.img_name,将对应的标签写入self.img_label里面\n",
    "    def __init__(self, img_path, txt_path, dataset='', data_transforms=None, loader=default_loader):\n",
    "        with open(txt_path) as input_file:\n",
    "            lines = input_file.readlines()\n",
    "            self.img_label = [int(line.strip()) for line in lines]\n",
    "        \n",
    "        self.img_name = []\n",
    "        for root, dirs, files in os.walk(img_path):\n",
    "            for name in sorted(files):\n",
    "                self.img_name.append(os.path.join(img_path, name))\n",
    "        self.data_transforms = data_transforms\n",
    "        self.dataset = dataset\n",
    "        self.loader = loader\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_name)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        img_name = self.img_name[item]\n",
    "        label = self.img_label[item]\n",
    "        img = self.loader(img_name)\n",
    "        \n",
    "        if self.data_transforms is not None:\n",
    "            try:\n",
    "                img = self.data_transforms[self.dataset](img)\n",
    "            except:\n",
    "                print(f'Cannot transform images: {image_name}')\n",
    "                \n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs, use_gpu):\n",
    "    since = time.time()\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    " \n",
    "    for epoch in range(num_epochs):\n",
    "        begin_time = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    " \n",
    "        # Each epoch has a training and validation phase\n",
    "        # for phase in ['train','val']:\n",
    "        for phase in ['train']:\n",
    "            count_batch = 0\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    " \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    " \n",
    "            # Iterate over data.\n",
    "            for data in dataloders[phase]:\n",
    "                count_batch += 1\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    " \n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    " \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    " \n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                # print(outputs.data)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    " \n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                # statistics\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels.data).to(torch.float32)\n",
    " \n",
    "                # print result every 10 batch\n",
    "                if count_batch%10 == 0:\n",
    "                    batch_loss = running_loss / (batch_size*count_batch)\n",
    "                    batch_acc = running_corrects / (batch_size*count_batch)\n",
    "                    print('{} Epoch [{}] Batch [{}] Loss: {:.4f} Acc: {:.4f} Time: {:.4f}s'. \\\n",
    "                          format(phase, epoch, count_batch, batch_loss, batch_acc, time.time()-begin_time))\n",
    "                    begin_time = time.time()\n",
    " \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    " \n",
    "            # save model\n",
    "            if phase == 'train':\n",
    "                if not os.path.exists('output'):\n",
    "                    os.makedirs('output')\n",
    "                torch.save(model, 'output/resnet_epoch{}.pkl'.format(epoch))\n",
    " \n",
    "            # deep copy the model\n",
    "            # if phase == 'val' and epoch_acc > best_acc:\n",
    "            if epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    " \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    # print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    print('Best acc: {:4f}'.format(best_acc))\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch [0] Batch [10] Loss: 0.1670 Acc: 0.0063 Time: 149.0148s\n",
      "train Epoch [0] Batch [20] Loss: 0.1675 Acc: 0.0031 Time: 133.4940s\n",
      "train Epoch [0] Batch [30] Loss: 0.1673 Acc: 0.0073 Time: 132.8196s\n",
      "train Epoch [0] Batch [40] Loss: 0.1673 Acc: 0.0078 Time: 124.6034s\n",
      "train Epoch [0] Batch [50] Loss: 0.1669 Acc: 0.0100 Time: 127.5398s\n",
      "train Epoch [0] Batch [60] Loss: 0.1657 Acc: 0.0109 Time: 123.1182s\n",
      "train Epoch [0] Batch [70] Loss: 0.1646 Acc: 0.0129 Time: 123.6780s\n",
      "train Epoch [0] Batch [80] Loss: 0.1635 Acc: 0.0176 Time: 122.2542s\n",
      "train Epoch [0] Batch [90] Loss: 0.1624 Acc: 0.0201 Time: 122.9324s\n",
      "train Epoch [0] Batch [100] Loss: 0.1612 Acc: 0.0225 Time: 121.8843s\n",
      "train Epoch [0] Batch [110] Loss: 0.1600 Acc: 0.0256 Time: 122.2273s\n",
      "train Epoch [0] Batch [120] Loss: 0.1584 Acc: 0.0312 Time: 121.7766s\n",
      "train Epoch [0] Batch [130] Loss: 0.1571 Acc: 0.0346 Time: 121.5857s\n",
      "train Epoch [0] Batch [140] Loss: 0.1558 Acc: 0.0362 Time: 121.6656s\n",
      "train Epoch [0] Batch [150] Loss: 0.1543 Acc: 0.0423 Time: 121.8578s\n",
      "train Epoch [0] Batch [160] Loss: 0.1530 Acc: 0.0449 Time: 121.4884s\n",
      "train Epoch [0] Batch [170] Loss: 0.1518 Acc: 0.0471 Time: 123.2499s\n",
      "train Epoch [0] Batch [180] Loss: 0.1503 Acc: 0.0524 Time: 122.6435s\n",
      "train Epoch [0] Batch [190] Loss: 0.1491 Acc: 0.0553 Time: 122.0027s\n",
      "train Epoch [0] Batch [200] Loss: 0.1478 Acc: 0.0584 Time: 121.4742s\n",
      "train Epoch [0] Batch [210] Loss: 0.1466 Acc: 0.0625 Time: 121.6009s\n",
      "train Epoch [0] Batch [220] Loss: 0.1452 Acc: 0.0661 Time: 122.5258s\n",
      "train Epoch [0] Batch [230] Loss: 0.1439 Acc: 0.0715 Time: 120.9753s\n",
      "train Epoch [0] Batch [240] Loss: 0.1425 Acc: 0.0768 Time: 121.6859s\n",
      "train Epoch [0] Batch [250] Loss: 0.1412 Acc: 0.0814 Time: 121.9534s\n",
      "train Loss: 0.1409 Acc: 0.0836\n",
      "Epoch 1/4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Bottleneck. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------\n",
      "train Epoch [1] Batch [10] Loss: 0.1039 Acc: 0.2219 Time: 121.3327s\n",
      "train Epoch [1] Batch [20] Loss: 0.1051 Acc: 0.2016 Time: 121.5767s\n",
      "train Epoch [1] Batch [30] Loss: 0.1019 Acc: 0.2490 Time: 121.8542s\n",
      "train Epoch [1] Batch [40] Loss: 0.1003 Acc: 0.2516 Time: 121.3917s\n",
      "train Epoch [1] Batch [50] Loss: 0.0996 Acc: 0.2569 Time: 121.4477s\n",
      "train Epoch [1] Batch [60] Loss: 0.0984 Acc: 0.2625 Time: 122.2531s\n",
      "train Epoch [1] Batch [70] Loss: 0.0974 Acc: 0.2696 Time: 121.8416s\n",
      "train Epoch [1] Batch [80] Loss: 0.0970 Acc: 0.2727 Time: 121.0778s\n",
      "train Epoch [1] Batch [90] Loss: 0.0959 Acc: 0.2753 Time: 121.2371s\n",
      "train Epoch [1] Batch [100] Loss: 0.0956 Acc: 0.2759 Time: 120.9286s\n",
      "train Epoch [1] Batch [110] Loss: 0.0949 Acc: 0.2801 Time: 121.9893s\n",
      "train Epoch [1] Batch [120] Loss: 0.0944 Acc: 0.2826 Time: 120.9121s\n",
      "train Epoch [1] Batch [130] Loss: 0.0935 Acc: 0.2849 Time: 122.2959s\n",
      "train Epoch [1] Batch [140] Loss: 0.0930 Acc: 0.2873 Time: 122.2713s\n",
      "train Epoch [1] Batch [150] Loss: 0.0927 Acc: 0.2887 Time: 121.2997s\n",
      "train Epoch [1] Batch [160] Loss: 0.0921 Acc: 0.2941 Time: 123.0375s\n",
      "train Epoch [1] Batch [170] Loss: 0.0916 Acc: 0.2956 Time: 136.6047s\n",
      "train Epoch [1] Batch [180] Loss: 0.0910 Acc: 0.3002 Time: 136.9264s\n",
      "train Epoch [1] Batch [190] Loss: 0.0903 Acc: 0.3043 Time: 134.9898s\n",
      "train Epoch [1] Batch [200] Loss: 0.0897 Acc: 0.3094 Time: 125.7644s\n",
      "train Epoch [1] Batch [210] Loss: 0.0892 Acc: 0.3106 Time: 126.6013s\n",
      "train Epoch [1] Batch [220] Loss: 0.0886 Acc: 0.3135 Time: 124.4291s\n",
      "train Epoch [1] Batch [230] Loss: 0.0881 Acc: 0.3173 Time: 124.7922s\n",
      "train Epoch [1] Batch [240] Loss: 0.0875 Acc: 0.3202 Time: 124.6028s\n",
      "train Epoch [1] Batch [250] Loss: 0.0872 Acc: 0.3230 Time: 124.4972s\n",
      "train Loss: 0.0871 Acc: 0.3238\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Epoch [2] Batch [10] Loss: 0.0727 Acc: 0.4563 Time: 124.7314s\n",
      "train Epoch [2] Batch [20] Loss: 0.0732 Acc: 0.4328 Time: 125.0951s\n",
      "train Epoch [2] Batch [30] Loss: 0.0729 Acc: 0.4292 Time: 125.2186s\n",
      "train Epoch [2] Batch [40] Loss: 0.0731 Acc: 0.4234 Time: 125.0514s\n",
      "train Epoch [2] Batch [50] Loss: 0.0724 Acc: 0.4300 Time: 124.5469s\n",
      "train Epoch [2] Batch [60] Loss: 0.0719 Acc: 0.4292 Time: 124.5872s\n",
      "train Epoch [2] Batch [70] Loss: 0.0710 Acc: 0.4344 Time: 124.9020s\n",
      "train Epoch [2] Batch [80] Loss: 0.0699 Acc: 0.4441 Time: 122.1340s\n",
      "train Epoch [2] Batch [90] Loss: 0.0695 Acc: 0.4455 Time: 121.9198s\n",
      "train Epoch [2] Batch [100] Loss: 0.0692 Acc: 0.4469 Time: 121.3650s\n",
      "train Epoch [2] Batch [110] Loss: 0.0688 Acc: 0.4500 Time: 120.4968s\n",
      "train Epoch [2] Batch [120] Loss: 0.0684 Acc: 0.4539 Time: 120.8785s\n",
      "train Epoch [2] Batch [130] Loss: 0.0681 Acc: 0.4567 Time: 121.9059s\n",
      "train Epoch [2] Batch [140] Loss: 0.0679 Acc: 0.4558 Time: 121.3085s\n",
      "train Epoch [2] Batch [150] Loss: 0.0675 Acc: 0.4577 Time: 121.4484s\n",
      "train Epoch [2] Batch [160] Loss: 0.0674 Acc: 0.4582 Time: 121.2396s\n",
      "train Epoch [2] Batch [170] Loss: 0.0671 Acc: 0.4596 Time: 122.2474s\n",
      "train Epoch [2] Batch [180] Loss: 0.0668 Acc: 0.4618 Time: 120.7439s\n",
      "train Epoch [2] Batch [190] Loss: 0.0665 Acc: 0.4643 Time: 120.5220s\n",
      "train Epoch [2] Batch [200] Loss: 0.0661 Acc: 0.4663 Time: 121.4387s\n",
      "train Epoch [2] Batch [210] Loss: 0.0660 Acc: 0.4680 Time: 121.0153s\n",
      "train Epoch [2] Batch [220] Loss: 0.0658 Acc: 0.4680 Time: 120.5833s\n",
      "train Epoch [2] Batch [230] Loss: 0.0655 Acc: 0.4712 Time: 121.3671s\n",
      "train Epoch [2] Batch [240] Loss: 0.0650 Acc: 0.4747 Time: 122.0592s\n",
      "train Epoch [2] Batch [250] Loss: 0.0646 Acc: 0.4775 Time: 121.4182s\n",
      "train Loss: 0.0647 Acc: 0.4788\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Epoch [3] Batch [10] Loss: 0.0544 Acc: 0.5719 Time: 120.9820s\n",
      "train Epoch [3] Batch [20] Loss: 0.0531 Acc: 0.5719 Time: 120.8799s\n",
      "train Epoch [3] Batch [30] Loss: 0.0541 Acc: 0.5562 Time: 121.0655s\n",
      "train Epoch [3] Batch [40] Loss: 0.0537 Acc: 0.5578 Time: 121.2783s\n",
      "train Epoch [3] Batch [50] Loss: 0.0527 Acc: 0.5700 Time: 120.4991s\n",
      "train Epoch [3] Batch [60] Loss: 0.0528 Acc: 0.5693 Time: 121.3482s\n",
      "train Epoch [3] Batch [70] Loss: 0.0524 Acc: 0.5746 Time: 121.1723s\n",
      "train Epoch [3] Batch [80] Loss: 0.0524 Acc: 0.5742 Time: 121.2854s\n",
      "train Epoch [3] Batch [90] Loss: 0.0522 Acc: 0.5753 Time: 121.9321s\n",
      "train Epoch [3] Batch [100] Loss: 0.0521 Acc: 0.5734 Time: 120.3636s\n",
      "train Epoch [3] Batch [110] Loss: 0.0515 Acc: 0.5798 Time: 121.0539s\n",
      "train Epoch [3] Batch [120] Loss: 0.0512 Acc: 0.5839 Time: 121.8310s\n",
      "train Epoch [3] Batch [130] Loss: 0.0510 Acc: 0.5846 Time: 121.0129s\n",
      "train Epoch [3] Batch [140] Loss: 0.0509 Acc: 0.5837 Time: 120.3018s\n",
      "train Epoch [3] Batch [150] Loss: 0.0510 Acc: 0.5831 Time: 121.3049s\n",
      "train Epoch [3] Batch [160] Loss: 0.0511 Acc: 0.5811 Time: 120.8494s\n",
      "train Epoch [3] Batch [170] Loss: 0.0511 Acc: 0.5818 Time: 121.0809s\n",
      "train Epoch [3] Batch [180] Loss: 0.0513 Acc: 0.5800 Time: 120.8345s\n",
      "train Epoch [3] Batch [190] Loss: 0.0514 Acc: 0.5785 Time: 120.7493s\n",
      "train Epoch [3] Batch [200] Loss: 0.0514 Acc: 0.5778 Time: 121.0284s\n",
      "train Epoch [3] Batch [210] Loss: 0.0510 Acc: 0.5807 Time: 122.1249s\n",
      "train Epoch [3] Batch [220] Loss: 0.0509 Acc: 0.5817 Time: 122.7235s\n",
      "train Epoch [3] Batch [230] Loss: 0.0510 Acc: 0.5795 Time: 121.4926s\n",
      "train Epoch [3] Batch [240] Loss: 0.0509 Acc: 0.5792 Time: 121.5517s\n",
      "train Epoch [3] Batch [250] Loss: 0.0508 Acc: 0.5801 Time: 121.3025s\n",
      "train Loss: 0.0509 Acc: 0.5799\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Epoch [4] Batch [10] Loss: 0.0460 Acc: 0.6062 Time: 121.6213s\n",
      "train Epoch [4] Batch [20] Loss: 0.0428 Acc: 0.6406 Time: 121.1038s\n",
      "train Epoch [4] Batch [30] Loss: 0.0433 Acc: 0.6417 Time: 121.1475s\n",
      "train Epoch [4] Batch [40] Loss: 0.0418 Acc: 0.6508 Time: 122.7807s\n",
      "train Epoch [4] Batch [50] Loss: 0.0416 Acc: 0.6506 Time: 120.4747s\n",
      "train Epoch [4] Batch [60] Loss: 0.0408 Acc: 0.6620 Time: 125.8572s\n",
      "train Epoch [4] Batch [70] Loss: 0.0397 Acc: 0.6737 Time: 122.8178s\n",
      "train Epoch [4] Batch [80] Loss: 0.0392 Acc: 0.6770 Time: 121.0261s\n",
      "train Epoch [4] Batch [90] Loss: 0.0386 Acc: 0.6865 Time: 120.6776s\n",
      "train Epoch [4] Batch [100] Loss: 0.0381 Acc: 0.6925 Time: 120.5949s\n",
      "train Epoch [4] Batch [110] Loss: 0.0372 Acc: 0.6991 Time: 121.1867s\n",
      "train Epoch [4] Batch [120] Loss: 0.0370 Acc: 0.7031 Time: 120.9754s\n",
      "train Epoch [4] Batch [130] Loss: 0.0368 Acc: 0.7031 Time: 120.7736s\n",
      "train Epoch [4] Batch [140] Loss: 0.0367 Acc: 0.7065 Time: 122.0058s\n",
      "train Epoch [4] Batch [150] Loss: 0.0366 Acc: 0.7083 Time: 121.1873s\n",
      "train Epoch [4] Batch [160] Loss: 0.0363 Acc: 0.7115 Time: 122.1323s\n",
      "train Epoch [4] Batch [170] Loss: 0.0361 Acc: 0.7142 Time: 120.8074s\n",
      "train Epoch [4] Batch [180] Loss: 0.0360 Acc: 0.7139 Time: 121.2534s\n",
      "train Epoch [4] Batch [190] Loss: 0.0359 Acc: 0.7163 Time: 121.4597s\n",
      "train Epoch [4] Batch [200] Loss: 0.0355 Acc: 0.7197 Time: 121.4299s\n",
      "train Epoch [4] Batch [210] Loss: 0.0356 Acc: 0.7189 Time: 121.5159s\n",
      "train Epoch [4] Batch [220] Loss: 0.0354 Acc: 0.7212 Time: 121.4314s\n",
      "train Epoch [4] Batch [230] Loss: 0.0354 Acc: 0.7215 Time: 124.9771s\n",
      "train Epoch [4] Batch [240] Loss: 0.0353 Acc: 0.7234 Time: 124.6037s\n",
      "train Epoch [4] Batch [250] Loss: 0.0351 Acc: 0.7241 Time: 125.9026s\n",
      "train Loss: 0.0351 Acc: 0.7236\n",
      "Training complete in 260m 30s\n",
      "Best acc: 0.723600\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    " \n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "       # 'val': transforms.Compose([\n",
    "           # transforms.Resize(256),\n",
    "           # transforms.CenterCrop(224),\n",
    "           # transforms.ToTensor(),\n",
    "           # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "       # ]),\n",
    "    }\n",
    " \n",
    "    # use_gpu = torch.cuda.is_available()   # 用gpu跑的话，可以把注释去掉\n",
    "    # print(use_gpu)\n",
    " \n",
    "    batch_size = 32\n",
    "    num_class = 197  # 用196会报错\n",
    " \n",
    "    # image_datasets = {x: customData(img_path='/ImagePath',\n",
    "    #                                 txt_path=('/TxtFile/' + x + '.txt'),\n",
    "    #                                 data_transforms=data_transforms,\n",
    "    #                                 dataset=x) for x in ['train', 'val']}\n",
    " \n",
    "    image_datasets = {x: customData(img_path=r'./data/cars_train/',\n",
    "                                    txt_path='./'+ x + '.txt',\n",
    "                                    data_transforms=data_transforms,\n",
    "                                    dataset=x) for x in ['train']}  # ['train', 'val']\n",
    " \n",
    "    # wrap your data and label into Tensor\n",
    "    dataloders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True) for x in ['train']} # ['train', 'val']\n",
    " \n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train']}  # ['train', 'val']\n",
    " \n",
    "    # get model and replace the original fc layer with your fc layer\n",
    "    model_ft = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    # print(num_ftrs)\n",
    "    model_ft.fc = nn.Linear(num_ftrs, num_class)   # 将resnet最后全连接层的输出换成数据集的类别总数\n",
    " \n",
    "    # if use gpu\n",
    "    # if use_gpu:\n",
    "    #     model_ft = model_ft.cuda()\n",
    " \n",
    "    # define cost function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    " \n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.005, momentum=0.9)\n",
    " \n",
    "    # Decay LR by a factor of 0.2 every 5 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.2)\n",
    " \n",
    "    # multi-GPU\n",
    "    # model_ft = torch.nn.DataParallel(model_ft, device_ids=[0,1])\n",
    " \n",
    "    # train model\n",
    "    model_ft = train_model(model=model_ft,\n",
    "                           criterion=criterion,\n",
    "                           optimizer=optimizer_ft,\n",
    "                           scheduler=exp_lr_scheduler,\n",
    "                           num_epochs=EPOCH,\n",
    "                           use_gpu=False)\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "    # save best model\n",
    "    torch.save(model_ft,\"output/best_resnet.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
