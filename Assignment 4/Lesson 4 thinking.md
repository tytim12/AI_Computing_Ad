#### Thinking 1：ALS有什么应用场景

答：最小交替二乘法在初高中的数学场景，多用于线性和非线性回归的拟合。在机器学习中（本课）讲解的内容中用于求解矩阵分解的目标函数最优化问题，适用于解决有明确评分矩阵的应用场景，补全用户评分矩阵



#### Thinking 2：ALS进行矩阵分解的时候，为什么可以并行化处理

答：可以通过切割矩阵并行计算，最后再合并结果（基础的矩阵计算方法）



#### Thinking 3：梯度下降法中的批量梯度下降（BGD），随机梯度下降（SGD），和小批量梯度下降有什么区别（MBGD）

答：

1. **批量梯度下降**是每一次迭代使使用**所有样本**进行梯度更新。
   1. 优点是：
      1. 一次对所有样本进行操作，同时全量数据可以代表总体，**对极值的方向掌握更好**。
      2. **如果是凸函数，绝对可以找到最优点**；
   2. 缺点是：数据量大的时候**训练过程很慢**（不过迭代次数应该会更少）
2. **随即梯度下降**是每次迭代使用**一个**样本进行参数更新，而不是在全量数据上计算损失函数，使训练速度更快。但**缺点**是：
   1. 由于信息损失，**准确度会下降**，即使是凸函数也**无法线性收敛**，
   2. 并且有可能陷入**局部最优解**或者**落入鞍点**；
   3. 另外可能无法实现并行计算。
3. **小批量梯度下降**常见于深度学习模型，属于前两者的这种办法。每次迭代的时候使用**batch_size**指定使用样本的数量来更新参数。
   1. 优点：
      1. 通过矩阵运算，速度不会比SGD慢太多
      2. 迭代次数比SGD少很多
      3. 可并行处理
   2. 缺点：选在batch_size是个技术活，选的不好会有问题，比如爆内存。



#### Thinking 4：对数据进行可视化EDA都有哪些方式，你都是用过哪些工具？

答：目前做数据可视化更多的是看数据量、展示复杂度以及计算复杂度进行选择：

1. 数据量小，展示的内容比较简单时，一般选择excel即可；
2. 数据量较大，或者要展示比较复杂的可视化（如pivot table、堆叠图、气泡图或者地图渲染之类的），会选择Tableau，该软件对x、y轴和计算值的交互方式比较友好，计算也方便；
3. 如果需要计算一些比较复杂的变量，或者需要一些更复杂的展示方式，就会选择结合 matplotlib 和 seaborn，通过python先计算需要的数据，再可视化



#### Thinking 5：你阅读过和推荐系统/计算广告/预测相关的论文么？有哪些论文是你比较推荐的，可以分享到微信群中

答：目前还没阅读过计算广告相关的论文，但是有阅读cv相关的，比如最近读的一篇叫做《Learning Deep Features for Discriminative Localization》的论文，讲述神经网络最后的全链接层虽然可以得出物体分类，但是会使中间池化的定位能力给去掉，所以作者利用去掉全链接层之后做了一个图片定位和分类神经网络，看识别结果还是十分不错，在保证准确度的同时还优化了时间空间复杂度（不需要全连接）。

